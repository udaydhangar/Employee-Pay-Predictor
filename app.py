# -*- coding: utf-8 -*-
"""employee pay predictor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mCcGwebU9yrfEomxoDaz2smlzbLz5n8G
"""

import pandas as pd

data=pd.read_csv(r"/content/adult 3.csv")

data.head(10)

data.tail(3)

data.shape

#null values
data.isna().sum() #mean mdeian mode arbitrary

print(data.workclass.value_counts())

data.workclass.replace({'?':'Others'},inplace=True)
print(data['workclass'].value_counts())

print(data['occupation'].value_counts())

data.occupation.replace({'?':'Others'},inplace=True)
print(data['occupation'].value_counts())

data=data[data['workclass']!='Without-pay']
data=data[data['workclass']!='Never-worked']
print(data['workclass'].value_counts())

print(data.relationship.value_counts())

print(data.gender.value_counts())

data.shape

#outlier detection
import matplotlib.pyplot as plt   #visualization
plt.boxplot(data['age'])
plt.show()

data=data[(data['age']<=75)&(data['age']>=17)]

plt.boxplot(data['age'])
plt.show()

data.shape

plt.boxplot(data['capital-gain'])
plt.show()

plt.boxplot(data['capital-gain'])
plt.show()

plt.boxplot(data['educational-num'])
plt.show()

data=data[(data['educational-num']<=16)&(data['educational-num']>=5)]

plt.boxplot(data['educational-num'])
plt.show()

plt.boxplot(data['hours-per-week'])
plt.show()

data.shape

data=data.drop(columns=['education']) #redundant features removal

data

from sklearn.preprocessing import LabelEncoder   #import libarary
encoder=LabelEncoder()                       #create object
data['workclass']=encoder.fit_transform(data['workclass']) #7 categories   0,1, 2, 3, 4, 5, 6,
data['marital-status']=encoder.fit_transform(data['marital-status'])   #3 categories 0, 1, 2
data['occupation']=encoder.fit_transform(data['occupation'])
data['relationship']=encoder.fit_transform(data['relationship'])      #5 categories  0, 1, 2, 3, 4
data['race']=encoder.fit_transform(data['race'])
data['gender']=encoder.fit_transform(data['gender'])    #2 catogories     0, 1
data['native-country']=encoder.fit_transform(data['native-country'])

data

x=data.drop(columns=['income'])
y=data['income']
x

from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import joblib

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Apply scaler to training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

models = {
    "LogisticRegression": LogisticRegression(),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
plt.bar(results.keys(), results.values(), color='skyblue')
plt.ylabel('Accuracy Score')
plt.title('Model Comparison')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Define models
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    results[name] = acc
    print(f"{name}: {acc:.4f}")

# Get best model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
print(f"\n‚úÖ Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model
joblib.dump(best_model, "best_model.pkl")
print("‚úÖ Saved best model as best_model.pkl")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import joblib
# 
# # Load the trained model, scaler, and encoder
# model = joblib.load("best_model.pkl")
# scaler = joblib.load("scaler.pkl")
# encoder = joblib.load("encoder.pkl")
# 
# st.set_page_config(page_title="Employee Salary Classification", page_icon="üíº", layout="centered")
# 
# st.title("üíº Employee Salary Classification App")
# st.markdown("Predict whether an employee earns >50K or ‚â§50K based on input features.")
# 
# # Sidebar inputs (these must match your training feature columns)
# st.sidebar.header("Input Employee Details")
# 
# # ‚ú® Replace these fields with your dataset's actual input columns
# age = st.sidebar.slider("Age", 17, 75, 30)
# workclass = st.sidebar.selectbox("Work Class", ['Private', 'Self-emp-not-inc', 'Local-gov', 'Others', 'State-gov', 'Self-emp-inc', 'Federal-gov'])
# fnlwgt = st.sidebar.number_input("Final Weight", min_value=0, value=200000)
# educational_num = st.sidebar.slider("Educational Number", 5, 16, 10)
# marital_status = st.sidebar.selectbox("Marital Status", ['Never-married', 'Married-civ-spouse', 'Local-gov', 'Divorced', 'Widowed', 'Separated', 'Married-AF-spouse'])
# occupation = st.sidebar.selectbox("Job Role", [
#     "Tech-support", "Craft-repair", "Other-service", "Sales",
#     "Exec-managerial", "Prof-specialty", "Handlers-cleaners", "Machine-op-inspct",
#     "Adm-clerical", "Farming-fishing", "Transport-moving", "Priv-house-serv",
#     "Protective-serv", "Armed-Forces", "Others"
# ])
# relationship = st.sidebar.selectbox("Relationship", ['Own-child', 'Husband', 'Not-in-family', 'Unmarried', 'Wife', 'Other-relative'])
# race = st.sidebar.selectbox("Race", ['Black', 'White', 'Asian-Pac-Islander', 'Amer-Indian-Eskimo', 'Other'])
# gender = st.sidebar.selectbox("Gender", ['Male', 'Female'])
# capital_gain = st.sidebar.number_input("Capital Gain", min_value=0, value=0)
# capital_loss = st.sidebar.number_input("Capital Loss", min_value=0, value=0)
# hours_per_week = st.sidebar.slider("Hours per week", 1, 100, 40)
# native_country = st.sidebar.selectbox("Native Country", ['United-States', 'Mexico', 'Philippines', 'Germany', 'Puerto-Rico', 'Canada', 'El-Salvador', 'India', 'Cuba', 'England', 'Jamaica', 'South', 'China', 'Italy', 'Dominican-Republic', 'Vietnam', 'Guatemala', 'Columbia', 'Poland', 'Japan', 'Haiti', 'Portugal', 'Taiwan', 'Iran', 'Nicaragua', 'Greece', 'Peru', 'Ecuador', 'France', 'Ireland', 'Hong', 'Trinadad&Tobago', 'Cambodia', 'Laos', 'Thailand', 'Yugoslavia', 'Outlying-US(Guam-USVI-etc)', 'Honduras', 'Hungary', 'Scotland', 'Holand-Netherlands'])
# 
# 
# # Build input DataFrame (‚ö†Ô∏è must match preprocessing of your training data)
# input_df = pd.DataFrame({
#     'age': [age],
#     'workclass': [workclass],
#     'fnlwgt': [fnlwgt],
#     'educational-num': [educational_num],
#     'marital-status': [marital_status],
#     'occupation': [occupation],
#     'relationship': [relationship],
#     'race': [race],
#     'gender': [gender],
#     'capital-gain': [capital_gain],
#     'capital-loss': [capital_loss],
#     'hours-per-week': [hours_per-week],
#     'native-country': [native_country]
# })
# 
# # Preprocess input data
# for col in ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']:
#     input_df[col] = encoder.transform(input_df[col])
# 
# input_df_scaled = scaler.transform(input_df)
# 
# 
# st.write("### üîé Input Data")
# st.write(input_df)
# 
# # Predict button
# if st.button("Predict Salary Class"):
#     prediction = model.predict(input_df_scaled)
#     st.success(f"‚úÖ Prediction: {prediction[0]}")
# 
# # Batch prediction
# st.markdown("---")
# st.markdown("#### üìÇ Batch Prediction")
# uploaded_file = st.file_uploader("Upload a CSV file for batch prediction", type="csv")
# 
# if uploaded_file is not None:
#     batch_data = pd.read_csv(uploaded_file)
#     st.write("Uploaded data preview:", batch_data.head())
# 
#     # Preprocess batch data
#     for col in ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']:
#         batch_data[col] = encoder.transform(batch_data[col])
# 
#     batch_data_scaled = scaler.transform(batch_data)
# 
#     batch_preds = model.predict(batch_data_scaled)
#     batch_data['PredictedClass'] = batch_preds
#     st.write("‚úÖ Predictions:")
#     st.write(batch_data.head())
#     csv = batch_data.to_csv(index=False).encode('utf-8')
#     st.download_button("Download Predictions CSV", csv, file_name='predicted_classes.csv', mime='text/csv')

import joblib
joblib.dump(model, 'salary_model.pkl')

import joblib

# Get best model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
print(f"\n‚úÖ Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model, scaler, and encoder
joblib.dump(best_model, "best_model.pkl")
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(encoder, 'encoder.pkl')

print("‚úÖ Saved best model as best_model.pkl")
print("‚úÖ Saved scaler as scaler.pkl")
print("‚úÖ Saved encoder as encoder.pkl")